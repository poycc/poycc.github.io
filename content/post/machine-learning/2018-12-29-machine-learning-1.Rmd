---
title: 机器学习笔记-1（定义、监督学习、无监督学习）
author: ''
date: '2018-12-29'
slug: machine-learning-1
categories:
  - machine-learning
tags:
  - note
---

# What is machine learning？

## Arthur Samuel（1959）的定义

>Machine Learning : Field of study that give computers the ability to learn without being explicitly programmed.

**在进行特定编程情况下给予计算机学习能力的领域**。

Samuel的定义可以回溯到50年代，他编写了一个西洋棋程序。 这程序神奇之处在于，编程者自己并不是个下棋高手。但因为他太菜了，于是就通过编程，让西洋棋程序自己跟自己下了上万盘棋。通过观察哪种布局（棋盘位置）会赢，哪种布局会输，久而久之，这西洋棋程序明白了什么是好的布局， 什么样是坏的布局。然后就牛逼大发了，程序通过学习后， 玩西洋棋的水平超过了Samuel。这绝对是令人注目的成果。尽管编写者自己是个菜鸟，但因为 计算机有着足够的耐心，去下上万盘的棋， 没有人有这耐心去下这么多盘棋。通过这些练习，计算机获得无比丰富的经验，于是渐渐成为了 比Samuel更厉害的西洋棋手。

上述这个是有点不正式的定义， 也比较古老。

## 卡内基梅隆大学Tom Mitchell（1998）的定义

>A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P,improves with experience E.

一个程序被认为能从经验E中学习，解决任务T，达到 性能度量值P，当且仅当，有了经验E后，经过P评判，程序在处理T时的性能有所提升。

Example: playing checkers.

E = the experience of playing many games of checkers

T = the task of playing checkers.

P = the probability that the program will win the next game.

Machine learning algorithms：

目前主要两种学习算法类型为：监督学习（Supervised learning）和无监督学习（Unsupervised learning）。

此外，大家也许在后面的学习听到诸如强化学习 （Reinforcement learning）和推荐系统（Recommender systems）等名词。

# 监督学习（Supervised learning）

假如你想预测一下现在的房价，这是一个数据集，横轴是房子的大小，纵轴是房价。

![](/images/post/machine-learning/1.png)

根据给定数据，假设你朋友有栋房子，750平尺（70平米） 想知道这房子能卖多少，好卖掉。 

那么，学习算法怎么帮你呢？学习算法可以： 绘出一条直线，让直线尽可能匹配到所有数据。 

![](/images/post/machine-learning/2.png)

基于此，看上去，那个房子应该、可能、也许、大概 卖到15万美元（一平米两千刀！）。

但这不是唯一的学习算法。 可能还有更好的。比如不用直线了， 可能平方函数会更好， 即二次多项式更符合数据集。

![](/images/post/machine-learning/3.png)


**监督学习，意指给出一个算法， 需要部分数据集已经有正确答案。**

比如给定房价数据集， 对于里面每个数据，算法都知道对应的正确房价， 即这房子实际卖出的价格。算法的结果就是算出更多的正确价格，比如那个新房子， 你朋友想卖的那个。

用更术语的方式来定义， 

**监督学习又叫回归问题，（应该是回归属于监督中的一种） 意指要预测一个连续值的输出，比如房价。**

虽然从技术上，一般把房价记到美分单位。 所以实际还是个离散值，但通常把它看作实际数字， 是一个标量值，一个连续值的数，而术语回归， 意味着要预测这类连续值属性的种类。 

另一个监督学习的例子，我和一些朋友之前研究的领域。让我们来看医学记录，并预测胸部肿瘤是恶性良性。 

如果某人发现有胸部肿瘤，恶性肿瘤有害又危险， 良性肿瘤则是少害。显然人们很关注这个。

让我们看一个收集好的数据集， 假设在数据集中，横轴表示肿瘤的大小，纵轴我打算圈上0或1，是或否， 即肿瘤是恶性的还是良性的。

![](/images/post/machine-learning/4.png)

这是一个胸部肿瘤的数据集，横轴表示肿瘤的大小，纵轴表示肿瘤是否为良性的。

假如非常不幸，我们的胸部长了肿瘤，对应的机器学习算法就是，根据你的这个尺寸，估算出一个概率，即肿瘤为良性肿瘤的概率或者恶性肿瘤的概率。



当然这也是一个分类（Classification）问题。分类就是要预测一个离散值的输出。

这里是0/1，也就是良性/恶性。当然在分类问题当中，有时候会超过两个值的输出。

举个具体例子， 胸部肿瘤可能有三种类型，所以要预测离散值0，1，2，3 0就是良性肿瘤，没有癌症。 1 表示1号癌症，假设总共有三种癌症。 2 是2号癌症，3 就是3号癌症。 这同样是个分类问题，因为它的输出的离散值集合分别对应于无癌，1号，2号，3号癌症

![](/images/post/machine-learning/5.png)

在分类问题中，还有另一种作图方式 来描述数据。我画你猜。要用到些许不同的符号集合 来描绘数据。如果肿瘤大小作为唯一属性， 被用于预测恶性良性，可以把数据作图成这样。 使用不同的符号来表示良性和 恶性，即阴性和阳性。所以，不再统一画叉叉了， 改用圈圈来代表良性肿瘤，就像这样。 仍沿用X（叉叉）代表恶性肿瘤。希望你能明白。 我所做的就是，把在上面的数据， 映射下来。再用不同的符号， 圈和叉来分别代表良性和恶性。

![](/images/post/machine-learning/6.png)

在上例中，只使用了一个特征属性，即肿瘤块大小，来预测肿瘤是恶性良性。在其它机器学习问题里， 有着不只一个的特征和属性。例子，现在不只是知道肿瘤大小，病人年龄和肿瘤大小都知道了。这种情况下数据集如表图所示，有些病人，年龄、肿瘤已知，不同的病人，会有一点不一样，肿瘤恶性，则用叉来代表。所以，假设 有一朋友得了肿瘤。肿瘤大小和年龄 落在此处。那么依据这个给定的数据集，学习算法 所做的就是画一条直线，分开恶性肿瘤和良性肿瘤，所以学习算法会 画条直线，像这样，把两类肿瘤分开。

![](/images/post/machine-learning/7.png)

如果它在那边，学习算法就说你朋友的肿瘤在良性一边，因此更可能是良性的。

在上面的示例中，我们都只是使用到很少的特征计算，当处理无限多特征条件时，而计算机性能有限，因此我们需要使用一种叫做支持向量机的算法，来让电脑能够处理无限多的特征。

总结一下：

>Supervised Learning：

>>In supervised learning, we are given a data set and already know what our correct output should look like, having the idea that there is a relationship between the input and the output.

>>Supervised learning problems are categorized into "regression" and "classification" problems. In a regression problem, we are trying to predict results within a continuous output, meaning that we are trying to map input variables to some continuous function. In a classification problem, we are instead trying to predict results in a discrete output. In other words, we are trying to map input variables into discrete categories.

# 无监督学习（Unsupervised Learning）

在上面的监督学习中，在其数据集里面，每一个样本都被标注为正样本或者负样本。对于每一个样本，我们也清楚知道什么才是正确的答案。

![](/images/post/machine-learning/8.png)

在无监督学习中，我们没有属性或者标签这个概念了。也就是所有的数据都是一样的，没有什么区别。

![](/images/post/machine-learning/9.png)

所以在无监督学习中我们只有一个数据集，没人告诉我们该怎么做，我们也不知道每个数据点究竟是什么意思，相反，它只告诉我们，现在有一个数据集，你能在其中找到某种结构吗？ 对于给定的数据集，无监督学习算法可能判定，该数据集包含两个不同的聚类，你看，这是第一个聚类，然后这是另一个聚类。

![](/images/post/machine-learning/10.png)

基于给出的数据集，无监督学习算法可以给出不同的聚类，这就是所谓的聚类算法。

举个例子，例如看新闻的网页：news.google.com，其实原理和现在我们经常所提的聚合新闻一样，简单的说就是能够根据某一话题自行将同样关键词的新闻信息聚拢在一起，方便读者阅览。

![](/images/post/machine-learning/11.png)

谷歌新闻每天去收集成千上万的网络新闻，然后将他们分组，组成一个个的新闻专题。当我们点进去一个新闻专题的时候，就会有全球各地的媒体对于该新闻的报导。

下面是一个基因的例子。给定一组不同的个体，对于每一个不同的个体，检测它们是否拥有某个特定的基因，图中绿色、红色、黑色等就是展示了这些不同的个体是否拥有一个特定的基因的不同程度。然后我们运行一个聚类算法，把不同的个体归入不同的类。

![](/images/post/machine-learning/12.png)

因为我们没有提前告诉我们的算法，这种基因类型是具体属于哪一类的人，我们只是告诉算法，这里有一堆数据，然后让其自动的按照得到的类型把这些个体进行分类。

接下来还有讲到以下一些应用无监督学习或者聚类算法的例子：

1. 用来组织大型的计算机集群：找出趋向于协同工作的机器，如果将这些机器放在一起，将能够使数据中心更加高效的工作。
2. 用于社交网络的分析：使用算法对某种社交软件的好友进行分析，来区分出好友粘度。
3. 利用公司庞大的客户信息数据库，自动找出不同的市场分割，并自动将客户分到不同的细分市场中，以此来进行更有效的销售。
4. 进行天文数据分析。
5. 鸡尾酒宴问题：在实验对象不同距离的话筒前，说出不同的语言内容，然后利用计算机自动进行内容识别和分离。

总结一下：

>Unsupervised Learning

>>Unsupervised learning allows us to approach problems with little or no idea what our results should look like. We can derive structure from data where we don't necessarily know the effect of the variables.

>>We can derive this structure by clustering the data based on relationships among the variables in the data.

>>With unsupervised learning there is no feedback based on the prediction results.


笔记整理自Coursera吴恩达机器学习课程。